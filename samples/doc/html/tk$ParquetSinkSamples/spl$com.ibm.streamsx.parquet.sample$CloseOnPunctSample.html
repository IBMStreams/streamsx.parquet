<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xml:lang="en-us" lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="copyright" content="(C) Copyright 2005"/>
<meta name="DC.rights.owner" content="(C) Copyright 2005"/>
<meta name="DC.Type" content="reference"/>
<meta name="DC.Title" content="SPL File CloseOnPunctSample.spl"/>
<meta name="DC.Format" content="XHTML"/>
<meta name="DC.Identifier" content="spldoc_compilationunit"/>
<link rel="stylesheet" type="text/css" href="../../html/commonltr.css"/>
<link rel="stylesheet" type="text/css" href="../../html/spldoc.css"/>
<title>SPL File CloseOnPunctSample.spl</title>
</head>
<body id="spldoc_compilationunit">


<h1 class="title topictitle1">SPL File <tt class="ph tt">CloseOnPunctSample.spl</tt></h1>

<div class="body refbody">
<div class="section">
<p class="p">
<a class="xref" href="../toolkits/toolkits.html">Toolkits</a> &gt; <a class="xref" href="tk$ParquetSinkSamples.html">ParquetSinkSamples 1.0.2</a> &gt; <a class="xref" href="ns$com.ibm.streamsx.parquet.sample.html">com.ibm.streamsx.parquet.sample</a> &gt; CloseOnPunctSample.spl</p>

</div>

<div class="section"><h2 class="title sectiontitle splhead-1">Content</h2>
  
  <dl class="dl">
    <dt class="dt dlterm"/>
<dd class="dd"/>

    
      <dt class="dt dlterm splhead-2">Operators</dt>

      <dd class="dd">
<ul class="sl simple">
<li class="sli"><strong class="ph b"><a class="xref" href="spl$com.ibm.streamsx.parquet.sample$CloseOnPunctSample.html#spldoc_compilationunit__composite_operator__PartitionCloseOnPunctSample">PartitionCloseOnPunctSample</a></strong>: The sample demonstrates ParquetSink operator  closing output files every 30 seconds.
</li>

</ul>

      </dd>

    
  </dl>

</div>

<div class="section"><h2 class="title sectiontitle splhead-1">Composites</h2>
  
</div>

<div class="section" id="spldoc_compilationunit__composite_operator__PartitionCloseOnPunctSample"><h2 class="title sectiontitle splpart">composite PartitionCloseOnPunctSample</h2>
  
</div>

<div class="section">

<p class="p">The sample demonstrates ParquetSink operator  closing output files every 30 seconds. Note, that empty files won't be created if no new data arrived. 
</p>

</div>

<div class="section"><h2 class="title sectiontitle">Parameters</h2>

<ul class="sl simple">
<li class="sli"><strong class="ph b">hdfsUri</strong>
</li>

<li class="sli"><strong class="ph b">hdfsUser</strong>
</li>

<li class="sli"><strong class="ph b">hdfsRootPath</strong>
</li>

<li class="sli"><strong class="ph b">hdfsFileDir</strong>
</li>

<li class="sli"><strong class="ph b">hdfsFileName</strong>
</li>

<li class="sli"><strong class="ph b">biTable</strong>
</li>

<li class="sli"><strong class="ph b">parquetCompressionType</strong>
</li>

<li class="sli"><strong class="ph b">parquetSinkVMArgs</strong>
</li>

<li class="sli"><strong class="ph b">dataFile</strong>
</li>

<li class="sli"><strong class="ph b">flushPeriodSecs</strong>
</li>

</ul>

</div>

<div class="section">
</div>

<div class="section">
</div>

<div class="section"><h2 class="title sectiontitle splhead-2">Composite Operator Graph</h2>
  
</div>

<div class="section splgraph">
  <embed class="image" src="../../image/tk$ParquetSinkSamples/op$com.ibm.streamsx.parquet.sample$PartitionCloseOnPunctSample.svg" width="552" height="154"/>
</div>

<div class="section"><h2 class="title sectiontitle splhead-2">SPL Source Code</h2>
  
</div>


<div class="section">
   <pre class="pre codeblock">

 public composite PartitionCloseOnPunctSample {
 	
 	param
 		expression&lt;rstring&gt; $hdfsUri: getSubmissionTimeValue("hdfsUri");
 		expression&lt;rstring&gt; $hdfsUser : getSubmissionTimeValue("hdfsUser");
 		expression&lt;rstring&gt; $hdfsRootPath: getSubmissionTimeValue("hdfsRootPath");
 		expression&lt;rstring&gt; $hdfsFileDir: getSubmissionTimeValue("hdfsFileDir", "CloseOnPunctTest");
 		expression&lt;rstring&gt; $hdfsFileName: getSubmissionTimeValue("hdfsFileName", "MyFile");
 		expression&lt;rstring&gt; $biTable: getSubmissionTimeValue("biTable", "MY_TABLE");
 		expression&lt;rstring&gt; $parquetCompressionType: getSubmissionTimeValue("parquetCompressionType","snappy");
 		expression&lt;rstring&gt; $parquetSinkVMArgs: getCompileTimeValue("parquetSinkVMArgs","-Xmx4096m");
 		expression&lt;rstring&gt; $dataFile: getSubmissionTimeValue("dataFile", "partitionSampleData.txt");
 		expression&lt;float64&gt; $flushPeriodSecs: (float64)getSubmissionTimeValue("flushPeriodSecs", "30.0");
 		
 	graph
 		
 		/**
 		 * Read and Parse raw events
 		 */		
 		stream&lt;CompressionSample.RawNetworkEvent_t&gt; NetworkEvent = FileSource()
 		{
 			param
 				file: $dataFile;
 				format: csv;
 				separator: "|";
 				initDelay: 10.0;
 		}
 
 		/**
 		 * Add partition-specific attributes
 		 */
 		stream&lt;NetworkEvent, tuple&lt;int32 YEAR, int32 MONTH,  int32 DAY, int32 HOUR&gt;&gt; PartitionedNetworkEvent = Functor(NetworkEvent) {
 			logic 
 				state: {
 					mutable timestamp dt_orig_ts;
 				}
 				onTuple NetworkEvent: {
 					// original format 2014-07-28 12:42:45.618
 					dt_orig_ts = toTimestamp(Sys.YYYY_MM_DD_hh_mm_ss_mmm,dt_orig);
 				}
 			
 			output PartitionedNetworkEvent:
             	YEAR = (int32)year(dt_orig_ts), 
             	MONTH = ((int32)month(dt_orig_ts)) + 1, 
             	DAY = (int32)day(dt_orig_ts), 
              	HOUR = (int32)hour(dt_orig_ts);
 	
 		}
 	
 		/**
 		 * Generates trigger for parquet file close
 		 */
 		stream &lt;boolean flush&gt; FlushBeacon = Beacon() {
 			param
 				period : $flushPeriodSecs;
 			
 		}
 		
 		stream&lt;PartitionedNetworkEvent&gt; FlushControl = Custom(FlushBeacon) {
 			logic
 		        onTuple FlushBeacon : {
 					submit(Sys.WindowMarker, FlushControl) ;
 		        }
 		}
 		
 		/**
 		 * Write data to HDFS in parquet format. The results are partitioned on a day 
 		 * granularity level. Output files are closed every 30 seconds.
 		 */
 		stream&lt;rstring partition&gt; ParquetMetaData = ParquetSink(PartitionedNetworkEvent , FlushControl) {
 			param
 				hdfsUri : $hdfsUri ;
 				hdfsUser : $hdfsUser ;
 		    	rootPath : $hdfsRootPath + "/" + $hdfsFileDir;
 		 	    file: $hdfsFileName + "." + (rstring)getSeconds(getTimestamp()) + ".{ID}.dat" ;
 				autoCreate : false;
 		        compressionType : $parquetCompressionType ;
 				closeOnPunct : true ;
 				partitionKeyNames: "year", "month", "day", "hour";
                 partitionValueAttrNames: "YEAR", "MONTH", "DAY", "HOUR";   
 				skipPartitionAttrs : true ;
 				vmArg : $parquetSinkVMArgs;
      	        // set block size to 64M - default is 128M
      	        blockSize: 67108864;
 		}
 		
 		/**
 		 * Generates BigSQL statement for the new partition addition.
 		 * The command is useful for new partitions dynamic update.
 		 */
 		stream&lt;rstring command&gt; ParquetMetaDataCommand = Functor(ParquetMetaData)
 		{
 			output
 				ParquetMetaDataCommand :
 					command = "ALTER TABLE " + $biTable + " ADD IF NOT EXISTS PARTITION (" + regexReplace(partition, "/", ",", true) + ");\n" ;
 		}
 		
 		/**
 		 * Prints out partition update command to standard output
 		 */
 		() as sinkPrefixSink = FileSink(ParquetMetaDataCommand)   {
 		            param
 		                file : "/dev/stdout";
 		                flush: 1u;
 		}
 
 }

   </pre>

</div>

</div>


</body>
</html>